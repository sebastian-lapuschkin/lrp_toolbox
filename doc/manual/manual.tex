\documentclass[a4wide]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf


\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{fancyvrb}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}



% Definitions of handy macros can go here

\newcommand{\todo}[1]{{\color{blue}#1$^{\textrm{todo}}$}}
\newcommand{\x}{\boldsymbol{x}}

\newcommand{\mat}{$^\text{Matlab}$}
\newcommand{\py}{$^\text{python}$}


\begin{document}

\title{LRP Toolbox for Artificial Neural Networks 1.3.1 \\ ----- \\ Manual}

\author{Sebastian Lapuschkin \and Alexander Binder \and Gr\'egoire Montavon \and Maximilian Kohlbrenner \and Klaus-Robert M\"uller \and Wojciech Samek}

\maketitle

\tableofcontents

\newpage

\section{Overview}
This is the manual for the LRP Toolbox for Artificial Neural Networks,
an open-source implementation of the Layer-wise Relevance Propagation (LRP)\cite{bach15}
algorithm for deep learning architectures.
LRP is capable of decomposing the decision function $f(\cdot)$ of a given neural network model wrt to an input point $\x$ in order to compute \emph{relevance values} $R^{(1)}_d$ at input level explaining \emph{why} and \emph{how} the model predicts the way it does.

The computed relevance values describe whether the state of input component $x_d$ contributes towards the recognition of the classifier's prediction target if $R^{(1)}_d > 0$ --- or opposes it if $R^{(1)}_d < 0$ --- and can be visualized as a heatmap for visual assessment.
A detailed description of LRP can either in the original publication~\cite{bach15} or further below in Section~\ref{sec:lrp}.
A recent overview containing hints and tips regarding effective application of LRP, and an overview over applications in the sciences is given in~\cite{samek2020toward}.

The toolbox comes with platform-independent stand-alone implementations of LRP in Matlab and python and a plugin for the Caffe~\cite{jia2014caffe} Deep Learning Toolkit.
Models, Data and Results can be imported and exported as Matlab's \texttt{.mat} files, numpy's \texttt{.npy} or \texttt{.npz} files for python or ASCII-formatted plain text. For details about the supported formats for each implementation see Section \ref{sec:implementation}.

Both the Matlab and python code are fully documented and for each example implementations demonstrate the application of LRP at hand of the MNIST hand written digit data set \cite{lecun1998mnist}.
The LRP implementation for Caffe extends the respective classes and files with the needed functionality and operates directly on images and pre-trained model from the command line.
The most recent official release of the source code and example data and models are available from
\begin{center}
\url{https://github.com/sebastian-lapuschkin/lrp_toolbox}
\end{center}

The following Section \ref{sec:setup} will guide through the process of obtaining, setting up and running the LRP Toolbox for all supported programming languages. Section \ref{sec:lrp} explains the LRP Algorithm in theory and Section \ref{sec:implementation} the implementation thereof by giving an overview over the provided classes and functions. Section \ref{sec:contact} contains additional information, the answers to frequently asked questions and the authors' contact data.



\section{Setup and Execution}
\label{sec:setup}

\subsection*{Getting the latest toolbox version}
The latest official release of the LRP Toolbox is available from
\begin{center}
	\url{https://github.com/sebastian-lapuschkin/lrp_toolbox}
\end{center}




\subsection*{Platforms and Requirements}
The python and matlab implementations are available for systems running Linux, Windows and OSX due to the platform agnostic nature of python and Matlab. Caffe runs on Linux and OSX, however Caffe ports for Windows became available very recently on github (e.g. \url{https://github.com/happynear/caffe-windows}). Known and successfully tested minimum package requirements are:
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{python} & \textbf{Matlab} & \textbf{Caffe} \\
\hline
python$\geq$3.5.6	& Matlab 8.3.0.532 (R2014a) & \emph{Caffe-own requirements:}   \\
numpy$\geq$1.18.3   & (Image Processing Toolbox)  & Boost Libraries (1.55.0) \\
matplotlib$\geq$3.0.3	   &&  Protocol Buffers:  \\
scikit-image$\geq$0.15.0	   & &  \hspace{5mm} libprotobuf (2.5.0)\\
scikit-learn$\geq$0.22.2.post1			& & \hspace{5mm} protobuf-compiler (2.5.0)  \\
(cupy$\geq$5.0.0)			& & Google logging: libglogs (0.3.3)\\
	   & &  Google Flags: libgflags (2.0)\\
 & &  HDF5: libhdf5 (1.8.11)  \\
		   & & Google Snappy: libsnappy (1.1.0)\\
 & & LevelDB: libleveldb (1.15.0)\\
 		   & & Lightning Mem-mapped DB: \\
 & & \hspace{5mm}  liblmdb (0.9.10) \\
 & &  ATLAS \emph{OR} OpenBLAS \emph{OR} \\
	& & Intel Math Kernel Library \\
	& & (tested with: libatlas-base-dev 3.10.1) \\
 & &  OpenCV$\ge$2.4   \\\cline{3-3}
& &   \emph{for the LRP heatmap computation binaries:}\\
 & & ImageMagick (6.7.7) \\
\hline
\end{tabular}
\end{center}
where the requirement listing for the LRP implementation on Caffe only lists the additional requirements beyond those for the caffe itself, which can be taken from \url{http://caffe.berkeleyvision.org/installation.html}


\subsection*{Installing and Running}

\subsection*{Out of the box: using \emph{Singularity}}
% calculate LRP heatmaps for pre-trained models without need for coding
For Caffe, we offer a \emph{Singularity} image which enables a convenient way to calculate attribution maps with LRP and other implemented methods (\texttt{ctrl+f} for \texttt{``relpropopts.relpropformulatype''} in this manual) for pre-trained CNN models.
% example the installation process and workflow for the larger imagenet models, facilitates getting started
The image can be used as an example demonstrating the installation process and workflow. It helps getting started with the LRP toolbox for Caffe.
% miniintro: singularity
Singularity \cite{kurtzer2017singularity} is a container platform that offers a convenient workflow to run, store and share code in a controlled environment with good hardware management options.
% ease of use: all dependencies cleared
Inside the container, all dependencies are taken care of and experiments can be rerun on exactly the same hardware settings making them easily reproducible.
% reproducable
For more material on \emph{Singularity}, you may refer to the \emph{sylabs} website (e.g.,~\url{https://sylabs.io/singularity/}).
% \paragraph{Download and install singularity}
In order to download and install the \emph{Singularity} platform, follow the instructions in the user guide (\url{https://sylabs.io/guides/3.5/user-guide/quick\_start.html}).

% Build the image
The singularity image can be found in the \verb!lrp_toolbox/singularity! folder and  is built by calling
\begin{Verbatim}[frame = single]
cd <toolbox_location>/singularity
singularity build --fakeroot --force caffe-lrp-cpu-u16.04.sif caffe-lrp-cpu-u16.04.def
\end{Verbatim}
The resulting \verb!.sif! file has all necessary dependencies installed and contains demonstration files as well as the needed pre-trained models.

%run the demo
The container comes with a demo skript that calculates relevance scores for images on the caffe models.
It is called using \verb!singularity run! (or directly as an executable, assuming the required permission as have been set) and a configuration file, a filelist file and an output path need to be specified:
\begin{Verbatim}[frame = single]
[singularity run] ./caffe-lrp-cpu-u16.04.sif -c CONFIGPATH -f FILELISTPATH -p OUTPUTPATH
\end{Verbatim}
Examples for config and filelist files can be found in \verb!<toolbox_location>/caffe-master-lrp/demonstrator/!~.
Attention: the use of absolute paths for \verb!CONFIGPATH!, \verb!FILELISTPATH! and \verb!OUTPUTPATH!  is recomended.
take care that the file behind \verb!FILELISTPATH! only contains absolute paths as well.
For more information about the LRP parameter options that can be changed in the configfile, see below in Section~\nameref{sec:caffe_specifics}.

\subsubsection*{Matlab and python}
The toolbox implementations for Matlab and python can be run out of the box, given all requirements in Section \ref{sec:setup} are fulfilled. After downloading the toolbox as \texttt{.zip}- or \texttt{.tar.gz}-archives and unpacking and merging its contents to disk, the demo applications can be executed (with\verb| [optional]| substrings indicated by brackets) as
\begin{Verbatim}[frame = single]
cd <toolbox_location>/matlab
matlab -nodesktop -r lrp_[cnn_]demo
\end{Verbatim}
for the Matlab implementation and
\begin{Verbatim}[frame = single]
cd <toolbox_location>/python
python lrp_[cnn_]demo.py
\end{Verbatim}
for python. On systems running Ubuntu 14.04 LTS (or newer), executing
\begin{Verbatim}[frame = single]
cd <toolbox_location>/python
bash install.sh
\end{Verbatim}
will install all required software packages, and then execute the \texttt{lrp\_demo}. Please read and modify \texttt{install.sh} carefully to suit your needs.
Note that an installation of the \texttt{cupy} package for python enables GPU support for the Python-based LRP implementation.

\subsubsection*{Caffe open-source package}

\emph{Note that below information is deprecated for Linux versions newer that Ubuntu 16.04 LTS. We recommend sticking to the Singularity build described earlier to minimize headaches.}
\vspace{2mm}

The LRP implementation for Caffe has been forked from the Caffe repository on October 3rd 2015 (rc2). After fulfilling all requirements listed above, execute
\begin{Verbatim}[frame = single]
cd <toolbox_location>/caffe-master-lrp
make clean
make all
\end{Verbatim}
Note that the Caffe-based LRP implementation currently only supports execution only on CPUs and already provides a correspondingly configured \texttt{Makefile.config}.

After successfully building Caffe, navigate to the subdirectory \texttt{demonstrator} and execute \texttt{build.sh} (include and library paths might have to be adjusted) to compile the executables \texttt{lrp\_demo}, \texttt{lrp\_parallel\_demo}, \texttt{lrp\_demo\_minimaloutput} and \texttt{lrp\_parallel\_demo\_minimaloutput} for sequential and parallel heatmap computation respectively. Note that while the binaries ending in \texttt{\_minimaloutput} will only write out plain text relevance maps and the ten dominantly predicted classes, while the other binaries will also produce images showing the actual resized and padded network input, as well as a heatmap visualization as images.

 The provided script \texttt{download\_model.sh} may be used to download and extract the  BVLC reference Caffe network model. To use your own caffe files, simply adapt the configuration files.
\begin{Verbatim}[frame = single]
cd <toolbox_location>/caffe-master-lrp/demonstrator
./build.sh
./download_model.sh
\end{Verbatim}
The caffe heatmap computation binary then called as e.g.
\begin{Verbatim}[frame = single]
./lrp_demo ./config_sequential.txt ./testfilelist.txt ./
\end{Verbatim}
Where \texttt{config\textunderscore sequential.txt} is the config file for the sequentially operating binary. \texttt{testfilelist.txt} lists image names to compute heatmaps for, with an optional prediction target. The contents of both files are discussed further below in Section \nameref{sec:caffe_specifics}. The last parameter --- here \texttt{./} --- as a path prefix added to each image file in \texttt{testfilelist.txt}. Should the paths in \texttt{testfilelist.txt} be full paths already, \texttt{/} should be the working choice.
The first part of above command \texttt{./lrp\_demo ./config\_sequential.txt [...]} may be exchanged to \texttt{./lrp\_parallel\_demo ./config.txt [...]} to process all images listed in \texttt{./testfilelist.txt} in parallel at the cost of increased memory consumption.

On systems running Ubuntu 14.04 LTS or Ubuntu 16.04 LTS, executing
\begin{Verbatim}[frame = single]
cd <toolbox_location>/caffe-master-lrp
bash install.sh
\end{Verbatim}
will install all required software packages, build Caffe and the demonstrator application and compute a small set of heatmaps for chosen example images.
For arbitrary/newer Linux distributions, we recommend building LRP for Caffe using our Singularity container definition.

\section{LRP for Artificial Neural Networks Summarized}
\label{sec:lrp}

\subsection*{Refreshing neural network prediction}
Artificial neural networks are commonly built from layers of computation
\begin{align}
z_{ij} &  =  x_iw_{ij} \\
z_j & =  \sum\limits_i z_{ij} + b_j\\
x_j & =  g(z_j)
\end{align}
where $x_i$ is the $i$th index of the input $\x$ of a (hidden) layer $l$, with $w_{ij}$ connecting the $i$th unit from layer $l$ to the $j$th unit of the succeeding layer $l+1$.
The variables $z_{ij}$ describe the \emph{forward messages} from the input neurons $i$ to the output neurons $j$, which are then aggregated by summation together with a bias term $b_j$.
An optional non-linear activation function is described by $g$.
Commonly used non-linearities are the hyperbolic tangent $g(z_j) = \tanh(z_j)$, the rectifying linear unit (ReLU) $g(z_j) = \max(0,z_j)$ or a softmax function $g(z_j) = \exp(z_j)/\sum_{j'}\exp(z_{j'})$.

 Multilayer neural networks stack several of these layers, each of them composed of a greater number of neurons. This formulation of neural networks is also sufficient to cover a wide range of architectures such as the simple multilayer perceptron or convolutional neural networks.

\subsection*{LRP for Artificial Neural Networks}
While the forward pass through an artificial neural network sends messages from the nodes from one layer to the succeeding ones, computing a final layer prediction starting at the input step-by-step, LRP moves over the layers in opposite direction to resolve the classifier's output as \emph{relevance messages} $R^{(l,l+1)}_{i\leftarrow j}$ sent from a layer $l+1$ to its predecessor $l$:

Knowing the relevance $R_j^{(l+1)}$ of an upper layer neuron $j$ at layer $l+1$, the goal is to obtain a decomposition into relevance messages which can then be aggregated again at the receiving nodes $i$ in layer $l$. As expressed in \cite{bach15}, a set of constraints
\begin{align}
R_j^{(l+1)} & =  \sum\limits_{i} R_{i \leftarrow j}^{(l,l+1)}
\label{eq:c1}
\end{align}
\begin{align}
R_i^{(l)} & = \sum\limits_{j} R_{i \leftarrow j}^{(l,l+1)}
\label{eq:c2}
\end{align}
must hold for the total amount of relevance to remain constant, e.g.
\begin{align}
f(\x) = \dots = \sum\limits_{j \in (l+1)} R^{(l+1)}_j = \sum\limits_{i \in (l)} R^{(l)}_i = \dots = \sum\limits_{d=1}^{\dim(\x)} R^{(1)}_d
\label{eq:cons}
\end{align}
ensuring the relevance conservation principle of LRP holds.

Deep neural networks are sequences of linear or convolution layers alternating with non-linear activations and/or pooling steps and the decomposition process of LRP operates in a layer-by-layer manner.
In the case of a linear fully connected layer
\begin{align}
z_{ij} = x_iw_{ij} ~&~ z_j = \sum\limits_i z_{ij} + b_j
\end{align}
such a decomposition is immediately given by $R_{i\leftarrow j} = z_{ij}$.
Therefore, a first possible choice of  relevance decomposition is given as
\begin{align}
R^{(l,l+1)}_{i\leftarrow j} = \frac{z_{ij}}{z_j}\cdot R_j^{(l+1)}
\label{eq:lrp_naive}
\end{align}
easily showing to approximate the conservation properties of Equation \ref{eq:cons}. Specifically,
\begin{align}
\sum\limits_i R^{(l,l+1)}_{i\leftarrow j} = R_j^{(l+1)} \cdot (1 - \frac{b_j}{z_j})
\end{align}
since the bias term $b_j$ does inject information during the forward pass as an always active input node and absorbs (or injects) relevance during the application of LRP proportionately. Note that a treatment of the bias term as a weight connected and constantly activated input node  $x_0$ with $x_0w_{0j}=b_j$, above formula uniformly yields a decomposition into relevance messages proportionally to the forward messages~$R_{(i,j)}^{(l,l+1)}~\propto~z_{ij}$.
While the treatment of convolutional and pooling layers is identical to that of fully connected layers, activation layers operate in a component-wise manner, i.e. $z_{j} = g(x_i) \Leftrightarrow z_{ij}  = g(x_i)\delta_{ij}$, where $g(\cdot)$ is a non-linear activation function and $\delta_{ij}$ describes the kronecker delta.
Consequently, the relevance messages $R^{(l,l+1)}_{i\leftarrow j}$ for activation layers describe an identity function $R^{(l)}_i = R^{(l+1)}_j$, making LRP a piece-wise linear decomposition process for each layer.
However, the integration of the forward-passed and potentially non-linear activations $x_i$ into the $z_{ij}$ of Equation \ref{eq:lrp_naive} (and the following decompositions below), renders LRP an in overall non-linear and unsupervised per-sample explanation method.

Once a message decomposition formula has been selected from Equations \ref{eq:lrp_naive} to \ref{eq:lrp_flat} --- all of which are part of the toolbox implementation --- the lower layer relevances $R^{(l)}_i$ are computed as a sum aggregation of incoming messages in consistency with the constraints in Equation \ref{eq:c1} and\ref{eq:c2}:
\begin{align}
R_i^{(l)} = \sum\limits_j = R^{(l,l+1)}_{i \leftarrow j}
\end{align}




\subsection*{Decomposition Variants and Parameters}
\paragraph{The $\epsilon$-decomposition formula.}
The disadvantage of the decomposition in Equation \ref{eq:lrp_naive} is that relevance messages $R^{(l,l+1)}_{i\leftarrow j}$ may become unbounded for very small $z_j$, which can be circumvented by introducing a sign-dependant numerical stabilizer $\epsilon$ in the denominator.
\begin{align}
R^{(l,l+1)}_{i\leftarrow j} = \frac{z_{ij}}{z_j + \epsilon \cdot sign(z_j)}\cdot R_j^{(l+1)}
\label{eq:lrp_epsilon}
\end{align}
This approach, although being an easy to understand and straight-forward solution to the issue of numerical instability, does leak relevance into $\epsilon$ and even may fully absorb relevance if $\epsilon$ becomes very large.
The $\epsilon$-decomposition formula explains the predictor output ``as-is'', while control over noisy explanations may be exerted via setting $\epsilon$ to appropriate values.

\paragraph{The $\alpha-\beta$-decomposition formula.}
An alternative and numerically conservative stabilizing method is the $\alpha-\beta$-method (or shorter, just $\alpha$-decomposition).
This decomposition treats the activating and inhibiting activation factors of a layer separately, e.g. let $z_j^+ = \sum_i z^+_{ij} + b^+_j$ and $z_j^- = \sum_i z^-_{ij} + b^-_j$ with

\begin{align}
z^+_{ij} = \begin{cases} z_{ij} &;~ z_{ij} > 0 \\ 0  &;~ else \end{cases}
~\text{and}~
z^-_{ij} = \begin{cases} z_{ij} &;~ z_{ij} < 0 \\ 0  &;~ else \end{cases}
\end{align}
and $b^+$ and $b^-$ being subject to the same rule.
The relevance decomposition into messages $R_{i \leftarrow j}^{(l,l+1)}$ as a weighted combination of positive (activating) and negative (inhibiting) contributions is then calculated as
\begin{align}
R^{(l,l+1)}_{i\leftarrow j} = \left(\alpha\cdot\frac{z_{ij}^+}{z_j^+} + \beta\cdot\frac{z_{ij}^-}{z_j^-}\right)\cdot R_j^{(l+1)}
\label{eq:lrp_alphabeta}
\end{align}
Adding the constraint $\alpha + \beta = 1$ ensures the relevance conservation principle to hold and reduces the number of added free parameters to one.

This decomposition method is especially useful when paired with a networks making use of ReLU activation layers, since hidden layer inputs will always be $\geq 0$ and their pre-activation outputs also need to be $\geq 0$ to ``fire''. This means that positively weighted connections $w_{ij}$ --- which all factor into $z_{ij}^+$ --- propagate the inputs in an activatingly, while negative weights create deactivating messages $z_{ij}^-$. So by choosing $\alpha$ (and therefore $\beta$) appropriately, allows to choose what is backwards-propagated in terms of relevance. For example setting $\alpha = 1$, causes $\beta = 0$ will result in relevance maps which yield insight into which features cause neuron activations, while $\alpha=2, \beta=-1$ yields a more balanced explanation with still more focus on the neuron-exciting inputs. Be careful, however, with setting a variable to 0: Sum-pooling after a ReLu activation layer will only yield positive activations. Here, setting $\alpha=0,\beta=1$ will result in no heatmap at all, since there are no inhibiting layer inputs to propagate the relevance to.

\paragraph{The $w^2$-decomposition formula}
The $w^2$-rule was first introduced in \cite{MonArXiv16} and is obtained by choosing the closest root to $\x$ in direction of maximal descent when using Deep Taylor Decomposition. Although it might seem that this decomposition is independent to the input data, the resulting heatmap explanations are unique for each data point through the influence of $R^{(l)}$. The relevance messages for this decomposition compute as
\begin{align}
R^{(l,l+1)}_{i\leftarrow j} = \frac{w_{ij}^2}{\sum\limits_{i'} w_{i'j}^2}R^{(l)}_{j}
\label{eq:lrp_ww}
\end{align}
This decomposition might come in handy when the resulting relevance map when using Equations \ref{eq:lrp_epsilon} or \ref{eq:lrp_alphabeta} are too sparse for the intended purposes, e.g. because the input level activations include zero valued variables which can not absorb any relevance ($z_{ij} = 0w_{ij} = 0 \Rightarrow R^{(l,l+1)}_{i\leftarrow j} = 0$), or it is in general desirable to reduce the resolution of the explanatory heatmap.

\paragraph{Flat weight decomposition}
The flat weight decomposition removes any model- and data-dependant influence for the decomposed layer altogether (except model- and data-specific relevance input from $R^{(l+1)}$), by simply projecting the upper layer relevance values $R^{(l+1)}_{i\leftarrow j}$ uniformly towards their receptive fields.
\begin{align}
R^{(l,l+1)}_{i\leftarrow j} = \frac{1}{\sum\limits_{i'} 1}R^{(l)}_{j}
\label{eq:lrp_flat}
\end{align}
The resulting relevance maps will yield explanations of input representations in higher network layers, potentially changing the semantics of the heatmaps. This decomposition method is further discussed in \cite{BacICIP16}. Note that for fully connected layers, the application of Equation \ref{eq:lrp_flat} will yield completely uniform and structure-less relevance maps. Using Equation \ref{eq:lrp_ww} instead is advised.




\section{Implementation and Examples}
\label{sec:implementation}
This section will provide detailed information about the implementation of the LRP Toolbox and demonstrates the basic workflow.

\subsection*{How to use the toolbox: Parameters and Results}

The use of the LRP toolbox requires in general
\begin{itemize}
\item A pre-trained neural network model
\item Data for performing a neural network prediction and LRP
\item Parameters for the LRP algorithm (optional)
\end{itemize}
with the usual workflow consisting of the following steps:
\begin{enumerate}
\item Obtain trained classifier $f(\cdot)$ and data compatible with classifier
\item Forward-pass data $\x$ through classifier, obtain $y_{\text{pred}} = f(\x)$. The forward pass is not only necessary to obtain a prediction $y_{\text{pred}}$ but more importantly to populate the classifier's internal variables with information specific to $\x$.
\item Apply LRP to obtain input layer relevances $R^{(1)}_d$ explaining the decision of the classifier for $\x$ ...
	\begin{itemize}
		\item wrt to the prediction $y_{\text{pred}}$
		\item or: wrt to a chosen prediction target $y_{\text{choice}}$
	\end{itemize}
	by setting the desired final layer relevance as input to LRP. See \cite{bach15}, \texttt{mini.$\lbrace$py,m$\rbrace$}, \texttt{lrp\_demo.$\lbrace$py,m$\rbrace$} and \texttt{lrp\_cnn\_demo.$\lbrace$py,m$\rbrace$} for details and examples.
\item Visualize input-layer relevances $R_d^{(1)}$ as a heatmap (optional)
\end{enumerate}


\subsection*{Examples and Interpretation of Results}
The LRP Toolbox provides working examples on pre-trained models for the MNIST~\cite{lecun1998mnist} data sets for the python and Matlab implementations and an example implementation of an LRP application for arbitrary photographic image data for Caffe. Data and models for the Matlab and python examples in respective binary formats and a shared plain text format are provided accordingly. For Caffe, exemplary image data is provided within the download archives and a  reference model and corresponding meta information can be downloaded by following above installation steps.
In the following, minimal working examples for both Matlab and python demonstrate the basic workflow with Figure \ref{fig:example} presenting the resulting images. Both minimal working examples are included as \texttt{<toolbox\_path>/matlab/mini.m} and \texttt{<toolbox\_path>/python/mini.py} \\
\begin{minipage}[t]{.5\textwidth}
\subsubsection*{\vphantom{python} Matlab}
\input{./graphics/mini.m}
\end{minipage}
\begin{minipage}[t]{.5\textwidth}
\subsubsection*{python \vphantom{Matlab}}
\input{./graphics/mini.py}
\end{minipage}



\begin{figure}[h]
\centering
\subfloat[Matlab : true class]{\includegraphics[width=0.25\textwidth]{./graphics/hm_m.png}}
\hspace{0.11\textwidth}
\subfloat[python : true class]{\includegraphics[width=0.25\textwidth]{./graphics/hm_py.png}}
\hspace{0.11\textwidth}
\subfloat[python : class $2$]{\includegraphics[width=0.25\textwidth]{./graphics/hm_py2.png}}
\caption{(a) and (b) : Heatmap visualizations computed as a result of the execution of both above listed code samples. (c) : The input digit explained as a $2$ by setting input for \texttt{nn.lrp()} to \texttt{np.array([0,0,1,0,0,0,0,0,0,0])[na,:] $\ast$ YPred} (i.e. by masking the respective outputs of all other classes) . The image is a result of the python implementation.  For both languages, the input parameters in angle brackets specifying the loaded model and data locations have been set to\\
\texttt{ <model\_path> = '<toolbox\_path>/models/MNIST/long-rect.txt'} and\\
\texttt{ <data\_path> =  '<toolbox\_path>/data/MNIST/test\_images.txt'}\\
The resulting rgb-images have been written to a location specified by \texttt{<i\_path>}.
Slight differences in digit outlines and color hue are the result of internal differences of the used color maps and edge detection functions provided by Matlab and the respective python modules. The heatmaps themselves can be expected to be identical for both implementations, up to the limits numerical precision.}
\label{fig:example}
\end{figure}

\subsubsection*{Interpretation of Heatmap Scores}
LRP computes a relevance score $R_d^{(1)}$ for each component of the classifier input $x_d$ in its given state. For the given model (high) positive values $f(\x)$ indicate the presence of an object or concept in an input sample.
Likewise, positive values $R_d^{(1)}$ argue for evidence for the presence of a concept --- the (chosen) prediction target --- via the state of $x_d$.

Figures \ref{fig:example} (a) and (b) demonstrate heatmaps for an input digit showing a hand-written $7$ next to a heatmap visualizing the input layer relevance values rating the input pixel's contribution towards the detection of a digit $7$, as computed with the samples implementations in  \texttt{mini.$\lbrace$py,m$\rbrace$}. (High) positive scores are visualized in orange to red color, while colder color hues signify neutral (green) to negative (blue) contributions to the detection of class $7$.

Note that due to the heatmap the top horizontal bar of the digit has been identified as a striking feature of the detected class, the ''leg'' of the hand written digit is rated as less important. This can be explained as this feature can be shared by digit classes $2$,$4$ and $9$, while a straight horizontal bar at the top is not. Digits of class $5$ however might share this feature, yet (due to our observation) tend to be angled differently in general, e.g. sloping down to the left more.  Note the also strong positive evidence outside the written digit: At the bottom, a small area has been identified as containing high positive evidence speaking for class $7$, with a less pronounced counterpart to the right. This can be interpreted as the absence of color contributing to the $7$-ness of the data point. In other words: If those pixels would be colored black, the digit would more closely resemble a $2$. The same interpretation can be applied to the horizontal bar at the top of the image. LRP attributes high relevance to the blank pixels above and below the horizontal bar. Coloring those pixels black would cause the $7$ to resemble a thickly drawn digit $9$. Note the negative evidence --- speaking against the $7$-ness of the input digit --- to the left of the top bar of the $7$, explaining that the classifier would predict the input image as a seven with increased certainty, if the horizontal bar would be longer. This example shows, that heatmaps computed by LRP are not segmentation masks but rate each input unit --- on top of the object and in background areas --- according to how their state influences the prediction of the classifier output.

Figure \ref{fig:example} (c) demonstrates the capability of the LRP algorithm to explain \emph{would-be} decisions of a classifier, e.g. in the above case why and how the input digit resembles a $2$ in the eyes of the classifier, or what parts are considered \emph{wrong}. The classifier considers the empty space below the angle at the top of the seven as evidence for the digit being a $2$, yet attributes negative evidence to the digit's \emph{pointy end} to the top right, since the typical member of class $2$ can be expected to be more round in shape. The classifier also identifies most of the ''foot'' as missing (rather: as unexpected for the explanation target) in the input digit, in order for it to more closely resemble a digit $2$.

Pixel-wise explanation always need to be interpreted in context of the problem the classifier has been trained to solve, or vice versa provide an insight to the problem setting with its peculiarities in the first place (E.g. for an application of LRP leading to interesting discoveries about the Pascal VOC \cite{everingham2010pascal} data set, see \cite{lapuschkin2016analyzing}).





\subsection*{Implementation}

The Matlab and python stand-alone implementations of the LRP Toolbox are designed to be as identical as possible in structure, while the LRP code for Caffe is conceived as a plugin to replace existing neural network layer implementations. Throughout this section, the structure and functionality of the Matlab and python implementations will be described in detail, followed by a delimination of the modifications made to the Caffe code in oder to support LRP. Additionally to the descriptions of modules, packages and functions found below, a documentation can be found within the uncompiled code itself.

\subsubsection*{Efficiency}

The python implementation of the LRP functionality heavily relies on numpy for efficiency, which shares the the use of LAPACK and BLAS with Matlab. LRP for Caffe does currently only support (parellel) processing on the CPU, using ATLAS, OpenBLAS, etc .

\subsubsection*{Data Import / Export}

\begin{itemize}
\item[{\textbf{Data}}]
	\begin{itemize}
		\item \textbf{python} : Data can be read and written with \texttt{data\_io.read()} and \texttt{data\_io.write()} and is assumed to be block-formatted as a $[N \times D]$ matrix. Supported are plain text ascii-matrices as \texttt{.txt} files, numpy's \texttt{.npy} and \texttt{.npz} formats and also \texttt{.mat} files via \texttt{scipy.io}. For the latter, the toolbox assumes the file to contain one matrix accessible via the key \emph{data}.
		\item \textbf{Matlab} : The Matlab implementation realizes data IO via \texttt{+data\_io.read()} and \texttt{+data\_io.write()} and supports \texttt{.mat} files next to plain text ascii-matrices in $[N \times D]$ block format.
		\item \textbf{Caffe} : The add-on for Caffe loads images using ImageMagick and thus supports a wide range of image data including JPEG and PNG.
	\end{itemize}
\item[{\textbf{Models}}]
	\begin{itemize}
		\item \textbf{python} : The python implementation can read and write neural network model files via functions \texttt{model\_io.read()} and \texttt{model\_io.write()}. Supported are python's \texttt{pickle} object serialization format and a plain text file format shared with Matlab and described further below. Default file name extensions for the pickled in- and output format are \texttt{.nn} and \texttt{.pickle} and \texttt{.txt} for the plain text description of the model. See the manual for details.
		\item \textbf{Matlab} : Supported are the with python shared plain text model description via \texttt{.txt} files and \texttt{.mat} files holding model information. Reading and Writing can be realized using \texttt{+model\_io.read()} and \texttt{+model\_io.write()}.

		\item \textbf{Caffe} : It is able to read the models trained with the Caffe package, e.g. those from the Caffe Model Zoo.
		\end{itemize}

\item[{\textbf{Heatmaps}}]
	\begin{itemize}
		\item \textbf{python} : The output of raw heatmap data can be managed using the module \texttt{data\_io}. Visualizing and writing the heatmap as rgb images is achieved using the functions \texttt{render.hm\_to\_rgb()} and \texttt{render.save\_image()}. The former converts an input relevance matrix or vector using a color map to a rgb image and the latter combines and writes a series of images in various formats.
		\item \textbf{Matlab} : The Matlab implementation offers the same functionality as its python counterpart via correspondingly named functions provided in package \texttt{+render}. An example on how to use these functions to draw and save heatmaps is given in the demo implementation.
		\item \textbf{Caffe} : The C++ version outputs four files into the path specified in the configfile as \texttt{standalone\textunderscore outpath}. The first two files,

\texttt{$\langle imagefilename\rangle$\textunderscore as\textunderscore inputted\textunderscore into\textunderscore the\textunderscore dnn.jpg} and

\texttt{$\langle imagefilename\rangle$\textunderscore heatmap.jpg} are simply the image how it looks like when it enters the quadratic receptive field of the neural network, and the resulting heatmap. While they are easily to be read in image viewers, they are unsuited for further processing of the heatmap. For that reason the file

\texttt{$\langle imagefilename\rangle$\textunderscore rawhm.txt} provides a the raw unnormalized heatmap scores as plain text. For a detailed explanation of the format of this file please refer to the manual. The last file, \texttt{$\langle imagefilename\rangle$\textunderscore toptenscores.txt} outputs the indices of the highest ranked classes and their scores.
Note that when using the \texttt{*\_minimaloutput} - implementations, only the plain text outputs will be generated.
%	The first line is the number of channels \texttt{(3)}. The second line gives height and width of the output. In the next line the heatmap scores are printed in the following order: the first row of channel 1, the second row of channel 1, ..., the last row of channel 1, the first row of channel 2, the second row of channel 2 ..., the last row of channel 2, the first row of channel 3 and so on. The fourth file,\emph{toptenscores.txt} consists of at most ten lines (less if the classification problem has less classes), corresponding to the classes with the highest prediction scores. Each line having the index of the class starting at zero and the output score from the top layer of the neural network. The noGUI version works slightly different. It created 4 files with the same content by appending to the original filename the suffixes \emph{\textunderscore as\textunderscore inputted\textunderscore into\textunderscore the\textunderscore dnn.jpg}, \emph{\textunderscore heatmap.jpg}  , \emph{\textunderscore rawhm.txt} and \emph{\textunderscore toptenscores.txt}. The resulting files are written into the directory given by the entry \emph{standalone\textunderscore outpath} in the config file.
%	}
			\end{itemize}
\end{itemize}


\subsubsection*{Matlab and python modules}
The stand-alone implementations of Matlab and python have been designed with a highly similar module or package structure within the possibilities of the programming languages. Modules for python are realized as single \texttt{*.py}-files containing all the module's functions. Synonymous to the modules of python are packages for Matlab, sharing the same names as their python counterparts. The difference is that packages for Matlab are realized as folders (with a leading \texttt{+} sign in front of the package name for Matlab to identify the folder as a package), with all implemented package functions or classes located as separate \texttt{.m}-files therein. The names and functionality of all implemented functions are to a large extend identical in between both stand-alone implementations and will therefore be outlined in unison. Notable differences will be highlighted in the respective descriptions using the flags $<$Matlab-specific$>$\mat and $<$python-specific$>$\py in case certain traits are not shared between the implementations. The descriptions of modules and packages are synonymous for a structural description and will be considered interchangeable. The following description will start with explaining the functions \texttt{lrp\_demo}, \texttt{lrp\_cnn\_demo} and \texttt{mini} as entry points to example implementations first and continue with the module structure. For a more detailed in-depth description of class- and method signatures please refer to the source code.

Example implementations of the LRP pipeline:
\begin{itemize}
\item \texttt{lrp\_demo} : This demo loads the MNIST test data set and a pre-trained classifier with rectification activation units. After normalizing the test data, LRP is performed on a selection of test data points, followed by rendering and saving the produced heatmap. Examples on how to choose a LRP decomposition method or prediction targets are given yet commented out. This script displays each rendered heatmap to the user.

\item \texttt{lrp\_cnn\_demo} follows the structure of \texttt{lrp\_demo}, but instead uses a pre-trained LeNet-5 convolutional neural network. In this script, functionality for also setting lrp parameters for each neural network layer, as introduced in version 1.2.0 of this toolbox, are demonstrated.

\item \texttt{mini} : A minimal execution example for LRP for only one data point from the MNIST test data set.
\end{itemize}

Package structure:
\begin{itemize}
\item \texttt{data\_io} provides functionality for reading and writing block-formatted data matrices in various formats.
	\begin{itemize}

		\item \texttt{read(path, fmt)} reads a data matrix from disc, located at \texttt{path}. If \texttt{fmt} is not given, the correct file format is inferred from the extension of \texttt{path}. Supported extensions / values for \texttt{fmt} are \texttt{'npy'\py , 'npz'\py , 'txt' , 'mat'}. Returns a matrix\mat or numpy array\py.

		\item \texttt{write(data, path, fmt)} receives a data matrix \texttt{data} and writes it to \texttt{path} in format \texttt{fmt}. If \texttt{fmt} is not given, the correct file format is inferred from the extension of \texttt{path}. Supported extensions / values for \texttt{fmt} are \texttt{'npy'\py , 'npz'\py , 'txt' , 'mat'}.

	\end{itemize}
\item \texttt{model\_io} provides an IO interface to read and write serialized neural network models in various formats.
	\begin{itemize}
		\item \texttt{read(path, fmt)} reads a neural network model from \texttt{path}, assuming a format \texttt{fmt}. Should \texttt{fmt} not be given, it --- and with that the correct way to read --- will be inferred from the file name extension in \texttt{path}. Supported formats and values for \texttt{fmt} are \texttt{'pickle'\py , 'pickled'\py , 'nn'\py, 'txt', 'mat'\mat}, where the python-specific formats are implemented using python's \texttt{pickle} module and \texttt{txt} is a plain text model description format shared between Matlab and python explained further below. Returns the neural network model as an instance of \texttt{modules.Sequential}.


		\item \texttt{write(model, path, fmt)} writes a neural network model represented via an instance of \texttt{modules.Sequential} to \texttt{path} in a given output format \texttt{fmt}. Should \texttt{fmt} not be given, it will be inferred from the file name extension in \texttt{path}. Supported formats and values for \texttt{fmt} are \texttt{'pickle'\py , 'pickled'\py , 'nn'\py, 'txt', 'mat'\mat}, where the python-specific formats are implemented using python's \texttt{pickle} module and \texttt{txt} is a plain text model description format shared between Matlab and python explained further below.


	\end{itemize}
\item \texttt{modules}
	\begin{itemize}

		\item \texttt{Module} implements an abstract class for neural network modules, defining a common interface which all other classes inheriting \texttt{Module} implement. The inherited default behaviour of all method stubs is to do nothing when called.
	\begin{itemize}
	\item If not implemented by inheriting methods, the function \texttt{forward(X)} will return \texttt{X} without change.
	\item \texttt{set\_lrp\_parameters(lrp\_var,lrp\_param)} allows to pre-set lrp parameters per layer, with \texttt{lrp\_var} identifying the desired decomposition method per name as string type input, and \texttt{lrp\_param} providing a method-specific parameter.
	\item \texttt{lrp(R, lrp\_var, param)} performs LRP wrt to an initial relevance input \texttt{R} and a previously fed-forward batch of data via a call of \texttt{forward(X)}. The parameters \texttt{lrp\_var} and \texttt{param} are optional. If not given,  the model (e.g. each layer) tries to use pre-set lrp parameters or will default to the simple lrp implementation from Equation \ref{eq:lrp_naive}.

				\texttt{lrp\_param $\in$ $\lbrace$ None\py, []\mat,'none' , 'simple', 'epsilon','eps', 'alphabeta',} \texttt{'alpha','ww','w\^{}2','flat' $\rbrace$} defines the decomposition alternative to use for all layers during the application of LRP. By default, the simple decomposition method in Equation \ref{eq:lrp_naive} will be applied, or any specific lrp parameters set using \texttt{set\_lrp\_parameters}. Setting the parameter to \texttt{'epsilon'} or \texttt{'alphabeta'} will cause the application of Equations \ref{eq:lrp_epsilon} and \ref{eq:lrp_alphabeta} respectively. \texttt{'eps'} and \texttt{'alpha'} are short equivalents for both methods. \texttt{'ww'} or \texttt{'w\^{}2'} will apply Equation \ref{eq:lrp_ww} and \texttt{'flat'} will apply Equation \ref{eq:lrp_flat}. Some layers do have default fall-back decompositions when the provided decomposition choice does not make sense.

				The parameter \texttt{param} may be used to set the corresponding free parameters $\epsilon$ and $\alpha$ of both methods. Default value is \texttt{[]\mat} or \texttt{None\py}.
	\end{itemize}

		\item \texttt{Sequential} represents the instance of an artificial neural network.
			\begin{itemize}
				\item \texttt{Sequential(modules)} Constructor. The parameter \texttt{modules} is an enumerable collection\py / cell array\mat of instances of class \texttt{Module} as computational layers of the network.

				\item \texttt{forward(X)} receives an input \texttt{X}, propagates it through the network and populates the network with input-specific data and internal data representations. Returns a network output.

				\item \texttt{train(X, Y, Xval, Yval, batchsize, iters, lrate, lrate\_decay, lfactor\_initial, status, convergence, transform)} implements a training procedure for the neural network implementation, using the error backpropagation algorithm. \texttt{train} receives a set of training data \texttt{X}		 and training labels  \texttt{Y},   on which the network is trained over \texttt{iters} (default is 10000) training iterations with mini batches of \texttt{batchsize} (default 25) samples at a time. Every \texttt{status} (default is 250) training iterations, the network is evaluated on the validation data \texttt{Xval} with labels \texttt{Yval}. If no input for the validation set is provided the whole training data is used for estimating the prediction performance. A training iteration consists of a forward pass of a minibatch, a backward pass of the delta between the prediction and the expected results followed by an update step. The speed of learning is determined by \texttt{lrate} (default is 0.005). \texttt{lrate\_decay} controls whether and how the learning rate will diminish during trainig, depending on the network performance. The default value is \texttt{'none'}, with alternatives being \texttt{'linear'} and \texttt{'sublinear'}. \texttt{lfactor\_initial} (default 1.0) is a multiplicative factor to the base learning rate. Using this, with multiple consecutive calls of \texttt{train} allows for a step-wise decrease in the learning rate over the complete network training. \texttt{convergence} (-1) is an integer value defining the number of iterations allowed without measurable network improvements, until model convergence is declared and the training is stopped. Values smaller than zero will disable this convergence check. The input variable \texttt{transform} accepts the handle of a function, which is to be applied to each input batch. This allows for slight input transformations, such as the addition of noise, etc. Default value is \texttt{None}, which is equivalent to the application of an identity function (aka. does nothing).
				 \item \texttt{backward(DY)} performs a backward pass through the network, taking the error gradient \texttt{DY} as input.
				 \item \texttt{update(lrate)} updates the network modules, after the error gradient has been computed using \texttt{backward}. \texttt{lrate} is a multiplicative factor determining the training velocity.
				\item \texttt{lrp(R,lrp\_var, lrp\_param)}
				The method returns first layer relevance values $R_d^{(1)}$. See the description of  \texttt{modules.Module.lrp} for details.


				\item \texttt{clean()} iterates over all layers of the neural network and calls \texttt{clean()} on the implementing modules, removing temporary data necessary for LRP	which has been memorized during the forward pass. This method is called in \texttt{model\_io.write()}.
			\end{itemize}

		\item \texttt{Linear} represents a linear layer.
			\begin{itemize}
				\item \texttt{Linear(m,n)} creates a linear neural network layer instance with \texttt{m} input dimensions and \texttt{n} output dimensions.

				\item \texttt{forward(X)} performs a forward-pass of the input \texttt{X} and returns an \texttt{n} dimensional output by applying $Y  = \texttt{X}W + B$, where $W$ is a weight matrix, $B$ the bias term and $Y$ the output.

				\item \texttt{lrp(R, lrp\_var, param)} performs LRP with upper layer relevances $R^{(l+1)}$ and returns relevance values $R^{(l)}$ for the layer input. See the description of \texttt{modules.Module.lrp} for details on the possible range of parameters.

			\end{itemize}
		\item \texttt{Tanh} implements an activation layer with non-linear $\tanh$ units.
			\begin{itemize}
				\item \texttt{forward(X)} applies the $\tanh$ function to the input \texttt{X} and returns the result.
			\end{itemize}

		\item \texttt{Rect} implements a rectification activation layer.
			\begin{itemize}
				\item \texttt{forward(X)} computes and returns $\max(0,\texttt{X})$
			\end{itemize}

		\item \texttt{SoftMax} implements a soft-max normalization layer
			\begin{itemize}
				\item \texttt{forward(X)} computes and returns $\forall i ~ \frac{\exp(\texttt{X}_i)}{\sum_j \exp(\texttt{X}_j)}$ for each row of \texttt{X}
			\end{itemize}
	\end{itemize}
\item \texttt{render} provides functionality to draw and save relevances and heatmaps as rgb-images
	\begin{itemize}
		\item \texttt{digit\_to\_rgb(X, scaling, shape, cmap)} renders a given data point \texttt{X} as a rgb-image using a color map \texttt{cmap}. The parameter \texttt{shape} specifies the original shape of \texttt{X}, to which the data is reshaped. The default value depends on the default behaviour of \texttt{render.vec2im()}. \texttt{scaling} is a positive integer vector describing a scaling factor, by which the image is enlarged (after reshaping) by pixel value replication.
		\item \texttt{hm\_to\_rgb(R, X, scaling, shape, sigma, cmap, normalize)} operates in a similar manner as \texttt{render.digit\_to\_rgb}, but renders the input heatmap \texttt{R} as an rgb-image and uses the data point \texttt{X} to compute an outline to overlay it with the heatmap image. For Matlab, this requires the availability of the Image Processing Toolbox. The parameter \texttt{sigma} is forwarded to a call of a canny edge detector for computing the outline of \texttt{X}. \texttt{normalize} controls whether the input heatmap \texttt{R} is to be normalized such that $\max(|\texttt{R}|) = 1$. Returns the visualized heatmap as rgb-image (a $[H \times W \times 3]$ - sized matrix\mat or \texttt{numpy.ndarray}\py)
		\item \texttt{enlarge\_image(img, scaling)} receives a $[H \times W]$ or $[H \times W \times D]$ matrix\mat or \texttt{numpy.ndarray}\py \texttt{img} and a positive integer value \texttt{scaling} as scaling factor and returns a $[H\cdot\texttt{scaling} \times W\cdot\texttt{scaling}]$ or $[H\cdot\texttt{scaling} \times W\cdot\texttt{scaling} \times D]$ output of the same type by pixel value replication.
		\item \texttt{repaint\_corner\_pixels(rgbimg, scaling)} receives a $[H \times W \times 3]$ - sized rgb image as matrix\mat or \texttt{numpy.ndarray}\py and a positive integer value \texttt{scaling} and replaces the bottom right and top left pixel rgb values with the color mean of all neighbouring pixels, in order to mask artificial heatmap responses as a result setting relevance anchor values during heatmap normalization. \texttt{scaling} holds information about the pixel size \emph{after} scaling the image. This workaround was/is necessary for successfully applying color maps using matlab and has become obsolete for the python implementation with toolbox version 1.2.0, thus has been dectivated in \texttt{digit\_to\_rgb\py}.
		\item \texttt{vec2im(V, shape)} receives a matrix\mat or \texttt{numpy.ndarray}\py and returns it \texttt{shape}-shaped. If \texttt{shape} is not given, the algorithm tries to reshape \texttt{V} such that its side lengths are equal.
		\item \texttt{save\_image(rgb\_images, path, gap)} receives a series of rgb images in an enumerable container\py or cell array\mat and concatenates them horizontally. In between the images, a column of black pixels \texttt{gap} pixels wide is introduced. The assembled image is then returned as a  $[H \times W \times 3]$ - sized matrix\mat or \texttt{numpy.ndarray}\py and written to \texttt{path}, where the file name extension of \texttt{path} controls the output format.
	\end{itemize}
\end{itemize}



\subsubsection*{Caffe}

For implementing LRP for the Caffe open source framework, several source files have been edited to support the required functionality, which can then be used by the example implementations in subfolder \texttt{toolbox\_path/caffe-master-lrp/demonstrator/}. Modified files and changes made are listed below:
\begin{itemize}
\item \texttt{include/caffe/} : Contains the following modified header files which now define interfaces for LRP functionality
\begin{itemize}
	\item \texttt{common\_layers.hpp}
	\item \texttt{data\_layers.hpp}
	\item \texttt{layer.hpp}
	\item \texttt{loss\_layers.hpp}
	\item \texttt{net.hpp}
	\item \texttt{neuron\_layers.hpp}
	\item \texttt{relpropopts.hpp} : newly added file
	\item \texttt{vision\_layers.hpp}
\end{itemize}


\item \texttt{src/caffe/} : Contains the following modified code files implementing the LRP steps
\begin{itemize}
	\item \texttt{layer.cpp}
	\item \texttt{net.cpp}
	\begin{itemize}
		\item \texttt{layers/}
		\begin{itemize}
			\item \texttt{base\_conv\_layer.cpp}
			\item \texttt{concat\_layer.cpp}
			\item \texttt{conv\_layer.cpp}
			\item \texttt{data\_transformer.cpp}
			\item \texttt{dropout\_layer.cpp}
			\item \texttt{hinge\_loss\_multilabel\_layer.cpp} : added with version 1.0.1
			\item \texttt{image\_data\_layer\_multilabel.cpp} : added with version 1.0.1
			\item \texttt{inner\_product\_layer.cpp}
			\item \texttt{loss\_layer.cpp}
			\item \texttt{lrn\_layer.cpp}
			\item \texttt{lrn\_layer.cu}
			\item \texttt{neuron\_layer.cpp}
			\item \texttt{pooling\_layer.cpp}
			\item \texttt{relu\_layer.cpp}
			\item \texttt{softmax\_layer.cpp}
			\item \texttt{split\_layer.cpp}
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsubsection*{Relevant C++ Interfaces}
There are two different interfaces, in class \texttt{net} (in \texttt{net.hpp} and  \texttt{net.cpp})
\begin{verbatim}
  void net::Backward_Relevance(const std::vector<int> & classinds,
  vector<vector<double> > & rawhm,
  const relpropopts & ro);
\end{verbatim}
and
\begin{verbatim}
  void net::Backward_Relevance_multi(const std::vector< std::vector<int> > & classinds,
  vector< vector<vector<double> > > & rawhm,
  const relpropopts & ro);
\end{verbatim}

The first one computes the heatmap for exactly one image. The second computes heatmaps for multiple images in at once which is in line with the ability of Caffe to compute a parallel forward pass. See in the model definition files the initial \texttt{10} in
\begin{verbatim}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
\end{verbatim}
which can be found in the file \texttt{deploy.prototxt} as part of the model description.
This means that this model file allows to compute a 10-fold parallel forward pass. \texttt{void net::Backward\_Relevance\_multi} can be used with such a file to compute a 10-fold parallel LRP backward pass.
Both interfaces require a forward pass to be run before calling them. The result is at best undefined otherwise.



For the first interface:

 \texttt{classinds} contains the indices of all classes, for which the heatmap is to be computed as a composite of their respective network output scores.

\texttt{rawhm[ch][h+w*height]} contains the heatmap score for channel \texttt{ch} (\texttt{ch=0} is red, \texttt{ch=1} is green, \texttt{ch=2} is blue. The order is RGB unlike the internal BGR order of Caffe.), in y-coordinate \texttt{h} (\texttt{h=0} is the topmost coordinate of the image), and in x-coordinate \texttt{w} (\texttt{w=0} is the leftmost coordinate of the image).


The second interface is a vectorized version of the first interface, i.e. \texttt{classinds[k]} has the same meaning as \texttt{classinds} in the first image, being applied to the \texttt{k}-th image. The same holds for \texttt{rawhm[k]} which is the same as \texttt{rawhm} for the first interface, with the input corresponding to the \texttt{k}-th image.

\texttt{relpropopts} (found in \texttt{include/caffe/relpropopts.hpp}) is a class which carries the options used for LRP. The options are as follows:

\texttt{relpropopts.numclasses} the number of classes of  the classification problem

\texttt{relpropopts.relpropformulatype}:
\begin{itemize}
\item 0 for the $\epsilon$-type formula
\item 2 for the $\alpha-\beta$-type formula
\item 11 for Gradient
\item 26 for Deconvolution \cite{DBLP:conf/eccv/ZeilerF14}
\item 54 for $\epsilon$ and flat decompositions below a given layer
\item 56 for $\epsilon$ and $w^2$ decompositions below a given layer
\item 58 for $\alpha-\beta$ and flat decompositions below a given layer
\item 60 for $\alpha-\beta$ and $w^2$ decompositions below a given layer
\item 99 for Sensitivity Analysis \cite{DBLP:journals/corr/SimonyanVZ13}, i.e., the pixel-wise norm of the gradient
% new methods:
\item 100 for LRP composite (see \cite{lapuschkin2017understanding,kohlbrenner2019towards}): $\alpha-\beta$ for convolution layers, $\epsilon$ for the rest
\item 102 for LRP composite (see 100) and flat below a given layer
\item 104 for LRP composite (see 100) and $w^2$ below a given layer
\item 166 for Guided Backpropagation \cite{springenberg2014striving}
\end{itemize}


\texttt{relpropopts.alphabeta\_beta} the beta for the $\alpha-\beta$-type formula

\texttt{relpropopts.epsstab} the $\epsilon$ for the $\epsilon$-type formula

\texttt{relpropopts.lastlayerindex} is the index of choice of the highest layer, e.g. the starting point for LRP.

\texttt{auxiliaryvariable\_maxlayerindexforflatdistinconv} proves the layer index from which on either flat or $w^2$ relevance decomposition is performed (see \texttt{lrp.relpropformulatype}s 54 to 60.

\texttt{relpropopts.firstlayerindex} is the index of the lowest layer at which relevance scores are taken and copied into the output vector of vectors \texttt{rawhm}.

the format of \texttt{rawhm} is determined by
\begin{verbatim}
const int channels = bottom_vecs_[i][0]->channels();
const int hei = bottom_vecs_[i][0]->height();
const int wid = bottom_vecs_[i][0]->width();
\end{verbatim}

Channel inversion is performed, which means that \texttt{rawhm[ch]} is taken from channel \texttt{C-1-ch}.

Other variables which are not supported in this release and have to be set to defaults (in parentheses) are:

\texttt{relpropopts.codeexectype} (0)

\texttt{relpropopts.lrn\_forward\_type} (0)

\texttt{relpropopts.lrn\_backward\_type} (1)

\texttt{relpropopts.maxpoolingtoavgpoolinginbackwardpass} (0)

\texttt{relpropopts.biastreatmenttype} (0)




\end{itemize}



\subsubsection*{The shared plain text file format}


		The plain text file format is shared among the Matlab and python implementations of the LRP Toolbox and describes
        the model by listing its computational layers line by line as

        \begin{verbatim}
<Layername_i> [<shape parameters>]
[<Layer_params_i>]
        \end{verbatim}

     	The following layers apply component-wise transformations to the input and thus only require a single line to be fully parameterized, e.g.

     	\begin{verbatim}
Rect
Tanh
SoftMax
Flatten
        \end{verbatim}
        for ReLu non-linearities, tanh-units and the softmax and flattening layer respectively. The linear layer implementation \texttt{modules.Linear} incorporates in raw text form as
        \begin{verbatim}
Linear m n
W
B
       \end{verbatim}
        with $m$ and $n$ being integer values describing the dimensions of the weight matrix $W$ as $[m \times n]$ and
        $W$ being the human readable ascii-representation of the matrix, where $W$ is reshaped to a s	ingle vector in C-order and written out as a
        white space separated line of floating point values.
        After the line describing $W$, the bias term $B$ is written out as a single line of $n$ white space separated floating point values.


		Both Max- and SumPooling layer share the same structure, except for the layer name:
		\begin{verbatim}
SumPool hpool wpool hstride wstride
		\end{verbatim}

		and
		\begin{verbatim}
MaxPool hpool wpool hstride wstride
		\end{verbatim}
        with $hpool$ and $wpool$ being the pooling operations respective height and width and $hstride$ and $wstride$ being the vertical and horizontal stride between pooling applications.

        Finally, Convolution layers are parsed out as
        \begin{verbatim}
Convolution hf wf df nf hstride wstride
W
B
        \end{verbatim}
        where $hstride$ and $wstride$ serve the same purpose as for the pooling layers, and $hf, wf, df$ and $nf$ are the filter bank's height, width and depth ( = input depth = number of input channels) and number of filters ( = output depth = number of output channels) respectively. As with the Linear layer $W$ are the learned weights, reshaped in C-order to a single vector written out as a single line of white-space separated values. $B$ is the vector if bias terms of the layer, equalling in length to $nf$.

        An example of a simple network trained to solve the \texttt{XOR}-problem is given below. The model file is also included as plain text in \texttt{<toolbox\_path>/models/XOR/xor\_net\_small.txt}

\subsubsection*{XOR-Solving Example Network}
\input{./graphics/xor_net_small.txt}

\section{Caffe specifics}
\label{sec:caffe_specifics}

\subsection*{Caffe output formats}


The C++ version outputs four files into the path specified in the configuration file as \texttt{standalone\textunderscore outpath}:

The first two files are

\texttt{$\langle imagefilename\rangle$\textunderscore as\textunderscore inputted\textunderscore into\textunderscore the\textunderscore dnn.png} and

\texttt{$\langle imagefilename\rangle$\textunderscore heatmap.png}. Those files are simply the image as it enters the quadratic receptive field of the neural network, and the resulting heatmap. While they are easily to be read in image viewers, they are unsuited for further processing of the heatmap. Note that both image files are \emph{not} written out when using the implementations named \texttt{*\_minimaloutput}. This code only writes out the results as plain the text files described below.


\texttt{$\langle imagefilename\rangle$\textunderscore rawhm.txt} provides the raw unnormalized heatmap scores as plain text.
The format is as follows:

\begin{Verbatim}[frame=single]
C
H W
[row 1 of channel 1]
[...]
[row H of channel 1]
[row 1 of channel 2]
[...]
[row H of channel 2]
[...]
[row H of channel C]
\end{Verbatim}

Where \texttt{C} is the number of (color) channels, which usually is 3. \texttt{H} and \texttt{W} are the height and width of the output respectively, which are then followed by a concatenated plain text output of the heatmap responses for all channels, where each row holds \texttt{W} entries.


The last file,

\texttt{$\langle imagefilename\rangle$\textunderscore toptenscores.txt} outputs the indices of the highest ranked classes and their scores and consists of at most ten lines with each line listing the 0-based index of the corresponding class. It is less than ten lines, if the classification problem has less than ten classes.


\subsection*{Caffe image file syntax}

This file is denoted as \texttt{testfilelist.txt} in the above example. Each line contains two entries: Firstly, the path to the image. Secondly, after a white space character, an integer value.
If that value equals $-1$, then the heatmap is computed for the highest top-scoring class. If the integer is $-2$, then the heatmap is computed for the 5 top-scoring classes. Each output will be initialized with the score of the highest inner-product layer, unless the option \texttt{lastlayerindex} in the config file specifies a different layer. If the integer is non-negative, then the heatmap will be computed for the class with that index. An example \texttt{testfilelist.txt} is provided with this release.


\subsection*{Caffe config file syntax}

The configuration file syntax for LRP for Caffe is realized as pairs of lines, where the first line identifies the variable to be set and the second line delivering the value. Example configuration files \texttt{config.txt} and \texttt{config\_sequential.txt} are provided with this release.

\begin{itemize}
	\item \texttt{param\textunderscore file} (string) \\
File of the caffe layer definitions as text file. Usually has the ending \texttt{.prototxt}. Check whether the value  \texttt{dims: x} in the \texttt{prototxt} file is appropriate for your case. If you process only one image, you can set that to 1 and your code performs faster and uses less memory.

	\item \texttt{model\textunderscore file} (string) \\
	File containing the Caffe model weights, usually as a binary file.

	\item \texttt{mean\textunderscore file} (string) \\
Absolute path to the image mean which gets substracted from the input image. Format is a Caffe blob proto if the value of use\textunderscore mean\textunderscore file\textunderscore asbinaryprotoblob is a positive integer.

	\item \texttt{use\_mean\_file\_asbinaryprotoblob} (integer) \\
	Set it to a positive integer if you to load a Caffe blob protofile as mean file.

	\item \texttt{synsetfile} (string) \\
Absolute path to a file containing as many lines as number of classes, with each line being the class label of the respective class.

\item \texttt{lastlayerindex} (integer) \\
Index of the highest layer where to start back-propagating LRP scores. Possible choice: any non-negative value for an explicit layer index, or $-1$ for auto-detecting the lowest oftmax layer or $-2$ for auto-detecting the highest inner product layer.

 \item \texttt{firstlayerindex} (integer) \\
Possible choice: any non-negative value for an explicit layer index.

\item \texttt{numclasses} (integer) \\
Number of classes of the classification problem.

\item \texttt{baseimgsize} (integer)  \\
Size of the largest side of the image after resizing, should be larger than \texttt{netinwid} and \texttt{netinhei}.

\item \texttt{standalone\_outpath} (string) \\
Path where to output the heatmap files.

\item \texttt{standalone\_rootpath}  (string) \\
should be the name of a subdirectory in the full path name of the input image files. The part of the path, starting at this string is appended to \texttt{<standalone\_outpath>}. Exits with error if the full path of the input image file does not contain this string. In particular, for the outputs written into \texttt{standalone\_outpath}, the path structure is preserved starting with \texttt{standalone\_rootpath}. This is helpful when two input images have identical filenames but are residing in different subdirectories. Example:
\begin{itemize}
\item \texttt{standalone\_outpath} is \texttt{/home/user99/results/03102015}
\item Input file is \texttt{/home/user99/data/data25092015/cats/cat03.jpg}
\item \texttt{standalone\_rootpath} is \texttt{data25092015}
\end{itemize}
Then, outfiles are written as e.g. \texttt{~/home/user99/results/03102015/data25092015/cats/cat03.jpg\_rawhm.txt}


\item \texttt{relpropformulatype} (integer) \\
Set to 0 for the $\epsilon$-type formula,
2 for the $\alpha$-$\beta$-type formula,
11 for Gradient,
99 for Sensitivity Analysis and 26 for Deconvolution,
54 for $\epsilon$+flat,
56  for $\epsilon+w^2$,
58 for $\alpha-\beta$+flat
and 60 for $\alpha-\beta+w^2$.
166 selects Guided Backprop.
The numeric codes 100, 102 and 104 implement the currently recommended layer-dependent LRP decomposition approaches for feed-forward neural networks~\cite{kohlbrenner2019towards,samek2020toward}

\item \texttt{auxiliaryvariable\_maxlayerindexforflatdistinconv} (integer) \\
Defines the layer index below (and including) for which ---  for the  \texttt{relpropformulatype}s 54 to 60 and 100, 102, 104 --- either flat or $w^2$ decomposition is applied instead of either $\epsilon$ or $\alpha-\beta$.

\item \texttt{epsstab} (float) \\
Value of $\epsilon$ for the $\epsilon$-type formula. Must be non-negative.

\item \texttt{alphabeta\_beta} (float) \\
Value of $\beta$ for the $\alpha$-$\beta$-type formula. Must be non-negative.


\end{itemize}









\section{Contact and Support}
\label{sec:contact}

For answers, help and support, please contact:\\
\begin{tabular}{lrcl}
Sebastian Lapuschkin  & \texttt{sebastian.lapuschkin} & \hspace{-5mm} \texttt{@} & \hspace{-5mm} \texttt{hhi.fraunhofer.de}\\
Alexander Binder  & \texttt{alexabin} & \hspace{-5mm} \texttt{@} & \hspace{-5mm} \texttt{ifi.uio.no}\\
Wojciech Samek  & \texttt{wojciech.samek} & \hspace{-5mm} \texttt{@} & \hspace{-5mm} \texttt{hhi.fraunhofer.de}
\end{tabular}


\bibliographystyle{plain}
\bibliography{manualbib}

\end{document}
